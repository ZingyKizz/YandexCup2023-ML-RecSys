{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ade1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: AVX2\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import zipfile\n",
    "import tqdm\n",
    "import gc\n",
    "import nmslib\n",
    "from collections import defaultdict, Counter\n",
    "import copy\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bad7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=0):\n",
    "    import random\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f699545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(f):\n",
    "    return f.name.rsplit(\"/\", 1)[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "def s3_objects(s3_client, bucket_name, keys, paths):\n",
    "    if paths is not None:\n",
    "        for path in paths:\n",
    "            yield path\n",
    "    else:\n",
    "        for key in keys:\n",
    "            s3_object = s3_client.get_object(Bucket=bucket_name, Key=key)[\"Body\"].read()\n",
    "            yield io.BytesIO(s3_object)\n",
    "            \n",
    "\n",
    "def load_track_embeddings(s3_client=None, bucket_name=None, keys=None, paths=None):\n",
    "    track_idx2embeds = {}\n",
    "    for s3_object in s3_objects(s3_client, bucket_name, keys, paths):\n",
    "        with zipfile.ZipFile(s3_object) as zf:\n",
    "            for file in zf.namelist():\n",
    "                if file.endswith(\".npy\"):\n",
    "                    with zf.open(file) as f:\n",
    "                        track_idx = int(extract_name(f))\n",
    "                        embeds = np.load(f)\n",
    "                        track_idx2embeds[track_idx] = embeds\n",
    "    return track_idx2embeds\n",
    "\n",
    "\n",
    "def load_tag_data(s3_client=None, bucket_name=None, keys=None, paths=None):\n",
    "    res = {}\n",
    "    for s3_object in s3_objects(s3_client, bucket_name, keys, paths):\n",
    "        with zipfile.ZipFile(s3_object) as zf:\n",
    "            for file in zf.namelist():\n",
    "                if file.endswith(\"train.csv\") or file.endswith(\"test.csv\"):\n",
    "                    with zf.open(file) as f:\n",
    "                        res[extract_name(f)] = pd.read_csv(f)\n",
    "    return res\n",
    "\n",
    "\n",
    "def load_data(base_path):\n",
    "    tag_data = load_tag_data(paths=[os.path.join(base_path, \"data.zip\")])\n",
    "    track_idx2embeds = load_track_embeddings(\n",
    "        paths=[\n",
    "            os.path.join(base_path, \"track_embeddings\", f\"dir_00{i}.zip\")\n",
    "            for i in range(1, 9)\n",
    "        ],\n",
    "    )\n",
    "    return tag_data, track_idx2embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de4277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TAGS = 256\n",
    "LENGTHS = (16, 32, 40, 64, 128, 10000)\n",
    "N_NEIGHBORS = (8, 16, 32, 64, 128, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e325e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ff5b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_data, track_idx2embeds = load_data(\"/Users/yaroslav.hnykov/Desktop/Study/VCS/YandexCUP2023/ML/RecSys/input_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e174c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a):\n",
    "    return a / np.linalg.norm(a)\n",
    "\n",
    "\n",
    "def get_embed_features(track_idx2embeds, track_idx):\n",
    "    track_embeds = track_idx2embeds[track_idx]\n",
    "    truncated_embeds = {\n",
    "        l: normalize(track_embeds[:l].mean(axis=0)) for l in LENGTHS\n",
    "    }\n",
    "    length = len(track_embeds)\n",
    "    return {\n",
    "        \"truncated_embeds\": truncated_embeds,\n",
    "        \"length\": length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe3f5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_embed_features(tag_data):\n",
    "    track_embed_features = {}\n",
    "    for track_idx in tqdm.tqdm(tag_data[\"track\"]):\n",
    "        track_embed_features[track_idx] = get_embed_features(track_idx2embeds, track_idx)\n",
    "    return track_embed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59afa51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51134/51134 [02:00<00:00, 423.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25580/25580 [02:09<00:00, 196.78it/s]\n"
     ]
    }
   ],
   "source": [
    "train_embed_features = get_track_embed_features(tag_data[\"train\"])\n",
    "test_embed_features = get_track_embed_features(tag_data[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e404a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del track_idx2embeds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2bfaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flatten_dataset(df, testing=False):\n",
    "    df = df.copy()\n",
    "    df[\"tag\"] = [list(map(str, range(NUM_TAGS)))] * len(df)\n",
    "    df = df.explode(\"tag\")\n",
    "    if not testing:\n",
    "        df[\"tags\"] = df[\"tags\"].str.split(\",\")\n",
    "        df[\"target\"] = df.apply(lambda x: str(x[\"tag\"]) in x[\"tags\"], axis=1).astype(int)\n",
    "        df.drop(columns=[\"tags\"], inplace=True)\n",
    "    return df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69401a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags_features(df):\n",
    "    df = df.copy()\n",
    "    df[\"tags\"] = df[\"tags\"].str.split(\",\")\n",
    "    df[\"n_tags\"] = df[\"tags\"].str.len()\n",
    "    df = df.explode(\"tags\")\n",
    "    tag_cnt = df.groupby(\"tags\").size().sort_values()\n",
    "    tags_features = {}\n",
    "    tags_features[\"pop_rank\"] = tag_cnt.rank(ascending=False).to_dict()\n",
    "    tags_features[\"pop_rank_upper_1\"] = (tag_cnt / tag_cnt.shift(1)).dropna().to_dict()\n",
    "    tags_features[\"pop_rank_lower_1\"] = (tag_cnt.shift(1) / tag_cnt).dropna().to_dict()\n",
    "    tags_features[\"pop_rank_upper_2\"] = (tag_cnt / tag_cnt.shift(3)).dropna().to_dict()\n",
    "    tags_features[\"pop_rank_lower_2\"] = (tag_cnt.shift(2) / tag_cnt).dropna().to_dict()\n",
    "    tags_features[\"pop_rank_upper_3\"] = (tag_cnt / tag_cnt.shift(3)).dropna().to_dict()\n",
    "    tags_features[\"pop_rank_lower_3\"] = (tag_cnt.shift(3) / tag_cnt).dropna().to_dict()\n",
    "    tags_features[\"individuality_mean\"] = df.groupby(\"tags\")[\"n_tags\"].mean().to_dict()\n",
    "    tags_features[\"individuality_std\"] = df.groupby(\"tags\")[\"n_tags\"].std().to_dict()\n",
    "    tags_features[\"individuality_max\"] = df.groupby(\"tags\")[\"n_tags\"].max().to_dict()\n",
    "    tags_features[\"individuality_min\"] = df.groupby(\"tags\")[\"n_tags\"].min().to_dict()\n",
    "    return tags_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d922145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_knn_indexes(train_embed_features):\n",
    "    simpleidx2trackidx = {}\n",
    "    vector_spaces = defaultdict(list)\n",
    "    for simple_idx, (track_idx, vfeatures) in enumerate(train_embed_features.items()):\n",
    "        simpleidx2trackidx[simple_idx] = track_idx\n",
    "        for length, v in vfeatures[\"truncated_embeds\"].items():\n",
    "            vector_spaces[length].append(v)\n",
    "\n",
    "    vector_spaces = {length: np.vstack(v) for length, v in vector_spaces.items()}\n",
    "    \n",
    "    knn_indexes = {}\n",
    "    for length, vector_space in vector_spaces.items():\n",
    "        index = nmslib.init(method=\"hnsw\", space=\"negdotprod\")\n",
    "        index.addDataPointBatch(vector_space)\n",
    "        index.createIndex({\"M\": 16,  \"efConstruction\": 100, \"post\": 2}, print_progress=True)\n",
    "        index.setQueryTimeParams({\"ef\": 90})\n",
    "        knn_indexes[length] = index\n",
    "    \n",
    "    return knn_indexes, simpleidx2trackidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "490d8588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbors(track_embed_features, knn_indexes, simpleidx2trackidx):\n",
    "    nearest_neighbors = {}\n",
    "    for track_idx, vfeatures in tqdm.tqdm(track_embed_features.items()):\n",
    "        nn = {}\n",
    "        for length, knn_index in knn_indexes.items():\n",
    "            vector = vfeatures[\"truncated_embeds\"][length]\n",
    "            neighbors_simple_indices = knn_index.knnQuery(vector, k=300)[0]\n",
    "            neighbors_track_indices = [\n",
    "                simpleidx2trackidx[si] \n",
    "                for si in neighbors_simple_indices \n",
    "                if simpleidx2trackidx[si] != track_idx\n",
    "            ]\n",
    "            nn[length] = neighbors_track_indices\n",
    "        nearest_neighbors[track_idx] = nn\n",
    "    return nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca0e70f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track2tags(tag_data):\n",
    "    df = tag_data.copy()\n",
    "    df[\"tags\"] = df[\"tags\"].str.split(\",\").apply(set)\n",
    "    return df.set_index(\"track\")[\"tags\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b11fdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_features(nearest_neighbors, track2tags):\n",
    "    knn_features = {}\n",
    "    for i in N_NEIGHBORS:\n",
    "        for l in LENGTHS:     \n",
    "            knn_features[f\"nn_{i}_l_{l}_tag_sh\"] = {}\n",
    "            knn_features[f\"nn_{i}_l_{l}_tracks_tag_sh\"] = {}\n",
    "    for track_idx, lneighbors in tqdm.tqdm(nearest_neighbors.items()):\n",
    "        for l, neighbors in lneighbors.items():\n",
    "            for i in N_NEIGHBORS:\n",
    "                cnt = Counter()\n",
    "                for n in neighbors[:i]:  \n",
    "                    cnt.update(track2tags[n])\n",
    "                total_tags = sum(cnt.values())\n",
    "                knn_features[f\"nn_{i}_l_{l}_tag_sh\"][track_idx] = {k: v / total_tags for k, v in cnt.items()}\n",
    "                knn_features[f\"nn_{i}_l_{l}_tracks_tag_sh\"][track_idx] = {k: v / i for k, v in cnt.items()}\n",
    "    return knn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab196d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "****************************************************\n",
      "\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "****************************************************\n",
      "\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n",
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************"
     ]
    }
   ],
   "source": [
    "knn_indexes, simpleidx2trackidx = build_knn_indexes(train_embed_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f1b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "track2tags = get_track2tags(tag_data[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59dd7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nearest_neighbors = find_nearest_neighbors(train_embed_features, knn_indexes, simpleidx2trackidx)\n",
    "train_knn_features = get_knn_features(train_nearest_neighbors, track2tags)\n",
    "\n",
    "del train_nearest_neighbors\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2051b668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25580/25580 [04:21<00:00, 97.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25580/25580 [04:59<00:00, 85.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_nearest_neighbors = find_nearest_neighbors(test_embed_features, knn_indexes, simpleidx2trackidx)\n",
    "test_knn_features = get_knn_features(test_nearest_neighbors, track2tags)\n",
    "\n",
    "del test_nearest_neighbors\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ac407f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del knn_indexes, track2tags, simpleidx2trackidx\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b0c4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(feats, \"feature_names.pkl\")\n",
    "\n",
    "FEATURE_NAMES = joblib.load(\"feature_names.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bc6080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(flattened_dataset, tag_data, knn_features, embed_features):\n",
    "    res = []\n",
    "    tags_features = get_tags_features(tag_data)\n",
    "    for row in tqdm.tqdm(flattened_dataset):\n",
    "        frow = row.copy()\n",
    "        for feature_name in FEATURE_NAMES:\n",
    "            if feature_name in tags_features:\n",
    "                frow[feature_name] = tags_features[feature_name].get(row[\"tag\"], -1)\n",
    "            elif feature_name in knn_features:\n",
    "                frow[feature_name] = knn_features[feature_name][row[\"track\"]].get(row[\"tag\"], -1)\n",
    "            elif feature_name == \"net_prediction\":\n",
    "                continue\n",
    "            elif feature_name == \"length\":\n",
    "                frow[feature_name] = embed_features[row[\"track\"]].get(\"length\", -1)\n",
    "        res.append(frow)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b77b700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chunked_features(tag_data, knn_features, embed_features, n_chunks=10, testing=False):\n",
    "    data = tag_data[\"test\"] if testing else tag_data[\"train\"]\n",
    "    for chunk_idx, chunk_data in enumerate(\n",
    "        np.array_split(data, n_chunks)\n",
    "    ):\n",
    "        print(f\"Proccessing chunk_idx = {chunk_idx}\")\n",
    "        features = make_features(\n",
    "            get_flatten_dataset(chunk_data, testing=testing), \n",
    "            tag_data[\"train\"], \n",
    "            knn_features, \n",
    "            embed_features\n",
    "        )\n",
    "        namebase = 'X_test' if testing else 'Xy_train'\n",
    "        with open(f\"../second_stage/base_features/{namebase}__chunk_idx={chunk_idx}.pkl\", mode=\"wb\") as f:\n",
    "            pickle.dump(features, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aadb097",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "make_chunked_features(tag_data, train_knn_features, train_embed_features, testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b097ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_knn_features, train_embed_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing chunk_idx = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1309696/1309696 [01:00<00:00, 21545.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing chunk_idx = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1309696/1309696 [02:00<00:00, 10911.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing chunk_idx = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1309696/1309696 [02:35<00:00, 8440.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing chunk_idx = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1309696/1309696 [01:10<00:00, 18538.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proccessing chunk_idx = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1309696/1309696 [01:15<00:00, 17398.50it/s]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "make_chunked_features(tag_data, test_knn_features, test_embed_features, n_chunks=5, testing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ba48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_knn_features, test_embed_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9791908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
